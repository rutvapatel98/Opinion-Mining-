{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "OpinionMining.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ1g7WJrUz2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IRS Term Paper Code\n",
        "#Kenal Butani- 16BIT130\n",
        "#Rutva Patel- 16BIT129\n",
        "import re\n",
        "import seaborn as sns\n",
        "import string\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "%matplotlib inline\n",
        "import numpy\n",
        "import pandas\n",
        "import nltk\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "import sklearn\n",
        "# from sklearn import cross_validation\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvf9fg4iUz2a",
        "colab_type": "code",
        "colab": {},
        "outputId": "1a3bb2a5-c0db-4aee-fe8d-92c748f0cac7"
      },
      "source": [
        "#Load csv file\n",
        "df = pandas.read_csv(\"textData.csv\",nrows = 1000)\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>author</th>\n",
              "      <th>SentimentText</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1956967341</td>\n",
              "      <td>0</td>\n",
              "      <td>xoshayzers</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>0</td>\n",
              "      <td>wannamama</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>0</td>\n",
              "      <td>cool1ky</td>\n",
              "      <td>1eral ceremony...gloomy friday...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1956967789</td>\n",
              "      <td>1</td>\n",
              "      <td>czareaquino</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1956968416</td>\n",
              "      <td>1</td>\n",
              "      <td>xkilljoyx</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1956968477</td>\n",
              "      <td>0</td>\n",
              "      <td>xxxPEACHESxxx</td>\n",
              "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1956968487</td>\n",
              "      <td>0</td>\n",
              "      <td>ShansBee</td>\n",
              "      <td>I should be sleep, but im not! thinking about ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1956968636</td>\n",
              "      <td>0</td>\n",
              "      <td>mcsleazy</td>\n",
              "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1956969035</td>\n",
              "      <td>0</td>\n",
              "      <td>nic0lepaula</td>\n",
              "      <td>@charviray Charlene my 1. I miss you</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1956969172</td>\n",
              "      <td>0</td>\n",
              "      <td>Ingenue_Em</td>\n",
              "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  sentiment         author  \\\n",
              "0  1956967341          0     xoshayzers   \n",
              "1  1956967666          0      wannamama   \n",
              "2  1956967696          0        cool1ky   \n",
              "3  1956967789          1    czareaquino   \n",
              "4  1956968416          1      xkilljoyx   \n",
              "5  1956968477          0  xxxPEACHESxxx   \n",
              "6  1956968487          0       ShansBee   \n",
              "7  1956968636          0       mcsleazy   \n",
              "8  1956969035          0    nic0lepaula   \n",
              "9  1956969172          0     Ingenue_Em   \n",
              "\n",
              "                                       SentimentText Unnamed: 4 Unnamed: 5  \\\n",
              "0  @tiffanylue i know  i was listenin to bad habi...        NaN        NaN   \n",
              "1  Layin n bed with a headache  ughhhh...waitin o...        NaN        NaN   \n",
              "2                  1eral ceremony...gloomy friday...        NaN        NaN   \n",
              "3               wants to hang out with friends SOON!        NaN        NaN   \n",
              "4  @dannycastillo We want to trade with someone w...        NaN        NaN   \n",
              "5  Re-pinging @ghostridah14: why didn't you go to...        NaN        NaN   \n",
              "6  I should be sleep, but im not! thinking about ...        NaN        NaN   \n",
              "7               Hmmm. http://www.djhero.com/ is down        NaN        NaN   \n",
              "8               @charviray Charlene my 1. I miss you        NaN        NaN   \n",
              "9         @kelcouch I'm sorry  at least it's Friday?        NaN        NaN   \n",
              "\n",
              "  Unnamed: 6  \n",
              "0        NaN  \n",
              "1        NaN  \n",
              "2        NaN  \n",
              "3        NaN  \n",
              "4        NaN  \n",
              "5        NaN  \n",
              "6        NaN  \n",
              "7        NaN  \n",
              "8        NaN  \n",
              "9        NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sX0eE28Uz2e",
        "colab_type": "code",
        "colab": {},
        "outputId": "15172e82-4143-4e38-a368-c120045f42eb"
      },
      "source": [
        "#1.Removing unicode\n",
        "result = []\n",
        "for text in df['SentimentText']:\n",
        "    text = re.sub(r'(\\\\u [0-9A-Za-z]+)',r'', text)       \n",
        "    text = re.sub(r'[^\\x00-\\x7f]',r'',text)\n",
        "    result.append(text)\n",
        "df['SentimentText'] = result\n",
        "df['SentimentText'] = df['SentimentText'].str.replace(\"[^a-zA-Z0-9#!?.@']\", \" \")\n",
        "df['SentimentText'].head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    @tiffanylue i know  i was listenin to bad habi...\n",
              "1    Layin n bed with a headache  ughhhh...waitin o...\n",
              "2                    1eral ceremony...gloomy friday...\n",
              "3                 wants to hang out with friends SOON!\n",
              "4    @dannycastillo We want to trade with someone w...\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkffkr3LUz2h",
        "colab_type": "code",
        "colab": {},
        "outputId": "bd84b877-d473-4089-a794-fe15c1accf28"
      },
      "source": [
        "#2.Replacing user names and urls by AT_USER and URL\n",
        "result = []\n",
        "for text in df['SentimentText']:\n",
        "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',text)\n",
        "    text = re.sub('@[^\\s]+','AT_USER',text)\n",
        "    text = re.sub('#[^\\s]+','',text)\n",
        "    result.append(text)\n",
        "df['SentimentText'] = result\n",
        "df['SentimentText'].head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    AT_USER i know  i was listenin to bad habit ea...\n",
              "1    Layin n bed with a headache  ughhhh...waitin o...\n",
              "2                    1eral ceremony...gloomy friday...\n",
              "3                 wants to hang out with friends SOON!\n",
              "4    AT_USER We want to trade with someone who has ...\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6IS3ElMUz2k",
        "colab_type": "code",
        "colab": {},
        "outputId": "43a55020-a66f-4b08-a93d-6b7e6ce15047"
      },
      "source": [
        "#3.removing abbrevations\n",
        "d = {' AFAIK ':' As Far As I Know ',' AFK ':' Away From Keyboard ',' ASAP ':' As Soon As Possible ',' ATK ':' At The Keyboard ',' ATM ':' At The Moment ',' A3 ':' Anytime, Anywhere, Anyplace ',' BAK ':' Back At Keyboard ',' BBL ':' Be Back Later ',' BBS ':' Be Back Soon ',' BFN ':' Bye For Now ',' B4N ':' Bye For Now ',' BRB ':' Be Right Back ',' BRT ':' Be Right There ',' BTW ':' By The Way ',' B4 ':' Before ','B4N':'Bye For Now','CU':'See You','CUL8R':'See You Later','CYA':'See You','FAQ':'Frequently Asked Questions','FC':'Fingers Crossed','FWIW':'For What It is Worth','FYI':'For Your Information','GAL':'Get A Life','GG':'Good Game','GN':'Good Night','GMTA':'Great Minds Think Alike','GR8':'Great!','G9':'Genius','IC':'I See','ICQ':'I Seek you','ILU':'I Love You','IMHO':'In My Honest/Humble Opinion','IMO':'In My Opinion','IOW':'In Other Words','IRL':'In Real Life','KISS':'Keep It Simple, Stupid','LDR':'Long Distance Relationship','LMAO':'Laugh My A.. Off','LOL':'Laughing Out Loud','LTNS':'Long Time No See','L8R':'Later','MTE':'My Thoughts Exactly','M8':'Mate','NRN':'No Reply Necessary','OMG':'Oh My God','OIC':'Oh I See','PITA':'Pain In The A..','PRT':'Party','PRW':'Parents Are Watching','QPSA?':'Que Pasa?','ROFL':'Rolling On The Floor Laughing','ROFLOL':'Rolling On The Floor Laughing Out Loud','ROTFLMAO':'Rolling On The Floor Laughing My A.. Off','SK8':'Skate','STATS':'Your sex and age','ASL':'Age, Sex, Location','THX':'Thank You','TTFN':'Ta-Ta For Now!','TTYL':'Talk To You Later',' U ':' You ','U2':'You Too','U4E':'Yours For Ever','WB':'Welcome Back','WTF':'What The F...','WTG':'Way To Go!','WUF':'Where Are You From?','W8':'Wait...','7K':'Sick'}\n",
        "result = []\n",
        "for text in df['SentimentText']:\n",
        "    for word in text.split():\n",
        "        if word in d:\n",
        "            text = text.replace(word, d[word])\n",
        "    result.append(text)\n",
        "df['SentimentText'] = result\n",
        "df['SentimentText'].head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    AT_USER i know  i was listenin to bad habit ea...\n",
              "1    Layin n bed with a headache  ughhhh...waitin o...\n",
              "2                    1eral ceremony...gloomy friday...\n",
              "3                 wants to hang out with friends SOON!\n",
              "4    AT_USER We want to trade with someone who has ...\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMtfRxHRUz2n",
        "colab_type": "code",
        "colab": {},
        "outputId": "75f5c091-f604-4c79-edf4-eda300111fba"
      },
      "source": [
        "#4.Replacing contractions\n",
        "contractions = {\"ain't\": \"am not / are not\",\"aren't\": \"are not / am not\",\"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he had / he would\",\"he'd've\": \"he would have\",\"he'll\": \"he shall / he will\",\"he'll've\": \"he shall have / he will have\",\"he's\": \"he has / he is\",\"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how has / how is\",\"i'd\": \"I had / I would\",\"i'd've\": \"I would have\",\"i'll\": \"I shall / I will\",\"i'll've\": \"I shall have / I will have\",\"i'm\": \"I am\",\"i've\": \"I have\",\"isn't\": \"is not\",\"it'd\": \"it had / it would\",\"it'd've\": \"it would have\",\"it'll\": \"it shall / it will\",\"it'll've\": \"it shall have / it will have\",\"it's\": \"it has / it is\",\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\"shan't've\": \"shall not have\",\"she'd\": \"she had / she would\",\"she'd've\": \"she would have\",\"she'll\": \"she shall / she will\",\"she'll've\": \"she shall have / she will have\",\"she's\": \"she has / she is\",\"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"so's\": \"so as / so is\",\"that'd\": \"that would / that had\",\"that'd've\": \"that would have\",\"that's\": \"that has / that is\",\"there'd\": \"there had / there would\",\"there'd've\": \"there would have\",\"there's\": \"there has / there is\",\"they'd\": \"they had / they would\",\"they'd've\": \"they would have\",\"they'll\": \"they shall / they will\",\"they'll've\": \"they shall have / they will have\",\"they're\": \"they are\",\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we had / we would\",\"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\"weren't\": \"were not\",\"what'll\": \"what shall / what will\",\"what'll've\": \"what shall have / what will have\",\"what're\": \"what are\",\"what's\": \"what has / what is\",\"what've\": \"what have\",\"when's\": \"when has / when is\",\"when've\": \"when have\",\"where'd\": \"where did\",\"where's\": \"where has / where is\",\"where've\": \"where have\",\"who'll\": \"who shall / who will\",\"who'll've\": \"who shall have / who will have\",\"who's\": \"who has / who is\",\"who've\": \"who have\",\"why's\": \"why has / why is\",\"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\"would've\": \"would have\",\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you had / you would\",\"you'd've\": \"you would have\",\"you'll\": \"you shall / you will\",\"you'll've\": \"you shall have / you will have\",\"you're\": \"you are\",\"you've\": \"you have\"}\n",
        "result = []\n",
        "for text in df['SentimentText']:\n",
        "    for word in text.split():\n",
        "        if word.lower() in contractions:\n",
        "            text = text.replace(word, contractions[word.lower()])\n",
        "    result.append(text)\n",
        "df['SentimentText'] = result\n",
        "df['SentimentText'].head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    AT_USER i know  i was listenin to bad habit ea...\n",
              "1    Layin n bed with a headache  ughhhh...waitin o...\n",
              "2                    1eral ceremony...gloomy friday...\n",
              "3                 wants to hang out with friends SOON!\n",
              "4    AT_USER We want to trade with someone who has ...\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aFoXE_fUz2q",
        "colab_type": "code",
        "colab": {},
        "outputId": "8681cbb2-c639-49a1-b32e-2f2c5d60bb8f"
      },
      "source": [
        "#5.Removing Numbers\n",
        "result = []\n",
        "for text in df['SentimentText']:\n",
        "    text = ''.join([i for i in text if not i.isdigit()])\n",
        "    result.append(text)\n",
        "df['SentimentText'] = result\n",
        "df['SentimentText'].head(5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    AT_USER i know  i was listenin to bad habit ea...\n",
              "1    Layin n bed with a headache  ughhhh...waitin o...\n",
              "2                     eral ceremony...gloomy friday...\n",
              "3                 wants to hang out with friends SOON!\n",
              "4    AT_USER We want to trade with someone who has ...\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKL2IeK7Uz2u",
        "colab_type": "code",
        "colab": {},
        "outputId": "654e757d-6cd8-408e-98fb-cd6df828d90f"
      },
      "source": [
        "#6. Replacing multiple punctuations\n",
        "result = []\n",
        "for text in df['SentimentText']:\n",
        "    text = re.sub(r\"(\\!)\\1+\", ' multiExclamation ', text)\n",
        "    text = re.sub(r\"(\\?)\\1+\", ' multiQuestion ', text)\n",
        "    text = re.sub(r\"(\\.)\\1+\", ' multiStop ', text)\n",
        "    result.append(text)\n",
        "df['SentimentText'] = result\n",
        "df['SentimentText'].head(5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    AT_USER i know  i was listenin to bad habit ea...\n",
              "1    Layin n bed with a headache  ughhhh multiStop ...\n",
              "2     eral ceremony multiStop gloomy friday multiStop \n",
              "3                 wants to hang out with friends SOON!\n",
              "4    AT_USER We want to trade with someone who has ...\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZV_3qJ6Uz2x",
        "colab_type": "code",
        "colab": {},
        "outputId": "35b12aac-e942-4d39-f4c3-60b3b35b2370"
      },
      "source": [
        "#7. Replacing negations with antonyms\n",
        "from nltk.corpus import wordnet\n",
        "def replace(word, pos=None):\n",
        "    antonyms = set()\n",
        "    for syn in wordnet.synsets(word, pos=pos):\n",
        "      for lemma in syn.lemmas():\n",
        "        for antonym in lemma.antonyms():\n",
        "          antonyms.add(antonym.name())\n",
        "    if len(antonyms) == 1:\n",
        "      return antonyms.pop()\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "def replaceNegations(text):\n",
        "    i, l = 0, len(text)\n",
        "    words = []\n",
        "    while i < l:\n",
        "      word = text[i]\n",
        "      if word == 'not' and i+1 < l:\n",
        "        ant = replace(text[i+1])\n",
        "        if ant:\n",
        "          words.append(ant)\n",
        "          i += 2\n",
        "          continue\n",
        "      words.append(word)\n",
        "      i += 1\n",
        "    return words\n",
        "\n",
        "result = []\n",
        "for text in df['SentimentText']:\n",
        "    text = replaceNegations(text)\n",
        "    result.append(text)\n",
        "for i in range(len(df['SentimentText'])):\n",
        "    df['SentimentText'][i] = ''.join(df['SentimentText'][i])\n",
        "df['SentimentText'] = result\n",
        "for i in range(len(df['SentimentText'])):\n",
        "    df['SentimentText'][i] = ''.join(df['SentimentText'][i])\n",
        "df['SentimentText'].head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/kenal/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/home/kenal/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    AT_USER i know  i was listenin to bad habit ea...\n",
              "1    Layin n bed with a headache  ughhhh multiStop ...\n",
              "2     eral ceremony multiStop gloomy friday multiStop \n",
              "3                 wants to hang out with friends SOON!\n",
              "4    AT_USER We want to trade with someone who has ...\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T6gkQ3PUz20",
        "colab_type": "code",
        "colab": {},
        "outputId": "a0b65e96-15b6-43e0-8d4f-162d5afa98fa"
      },
      "source": [
        "#8. Removing punctuation\n",
        "result = []\n",
        "for text in df['SentimentText']:\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    result.append(text)\n",
        "df['SentimentText'] = result\n",
        "df['SentimentText'].head(5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    AT_USER i know  i was listenin to bad habit ea...\n",
              "1    Layin n bed with a headache  ughhhh multiStop ...\n",
              "2     eral ceremony multiStop gloomy friday multiStop \n",
              "3                  wants to hang out with friends SOON\n",
              "4    AT_USER We want to trade with someone who has ...\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ9BbTxsUz23",
        "colab_type": "code",
        "colab": {},
        "outputId": "715b4f3e-7379-44ce-c68b-08311fb6d092"
      },
      "source": [
        "#10. Lowercasing\n",
        "result = []\n",
        "for text in df['SentimentText']:\n",
        "    text = text.lower()\n",
        "    result.append(text)\n",
        "df['SentimentText'] = result\n",
        "df['SentimentText'].head(5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    at_user i know  i was listenin to bad habit ea...\n",
              "1    layin n bed with a headache  ughhhh multistop ...\n",
              "2     eral ceremony multistop gloomy friday multistop \n",
              "3                  wants to hang out with friends soon\n",
              "4    at_user we want to trade with someone who has ...\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzhh7jgkUz26",
        "colab_type": "code",
        "colab": {},
        "outputId": "5d99edeb-350f-4769-d3af-cc50eefad1dd"
      },
      "source": [
        "#11. Removing stop words\n",
        "df['SentimentText'] = df['SentimentText'].apply(lambda x: x.split())\n",
        "from nltk.corpus import stopwords\n",
        "result = []\n",
        "for text in df['SentimentText']:\n",
        "    text = [w for w in text if not w in stopwords.words(\"english\")]\n",
        "    result.append(text)\n",
        "for i in range(len(df['SentimentText'])):\n",
        "    df['SentimentText'][i] = ''.join(df['SentimentText'][i])\n",
        "df['SentimentText'] = result\n",
        "for i in range(len(df['SentimentText'])):\n",
        "    df['SentimentText'][i] = ' '.join(df['SentimentText'][i])\n",
        "df['SentimentText'].head(5)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/kenal/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  if __name__ == '__main__':\n",
            "/home/kenal/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    at_user know listenin bad habit earlier starte...\n",
              "1    layin n bed headache ughhhh multistop waitin c...\n",
              "2      eral ceremony multistop gloomy friday multistop\n",
              "3                              wants hang friends soon\n",
              "4       at_user want trade someone houston tickets one\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NgJcOLlUz29",
        "colab_type": "code",
        "colab": {},
        "outputId": "74c02cd8-12be-47ce-a269-6a73d10ec608"
      },
      "source": [
        "#tokenization\n",
        "df['SentimentText'] = df['SentimentText'].apply(lambda x: x.split())\n",
        "df['SentimentText'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [at_user, know, listenin, bad, habit, earlier,...\n",
              "1    [layin, n, bed, headache, ughhhh, multistop, w...\n",
              "2    [eral, ceremony, multistop, gloomy, friday, mu...\n",
              "3                         [wants, hang, friends, soon]\n",
              "4    [at_user, want, trade, someone, houston, ticke...\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVEKkYUyUz3A",
        "colab_type": "code",
        "colab": {},
        "outputId": "fc3abce3-7d08-46dd-d93f-d2f374b5ffa4"
      },
      "source": [
        "#12. Stemming\n",
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "df['SentimentText'] = df['SentimentText'].apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
        "for i in range(len(df['SentimentText'])):\n",
        "    df['SentimentText'][i] = ' '.join(df['SentimentText'][i])\n",
        "df['SentimentText'].head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/kenal/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    at_us know listenin bad habit earlier start fr...\n",
              "1    layin n bed headach ughhhh multistop waitin ca...\n",
              "2      eral ceremoni multistop gloomi friday multistop\n",
              "3                                want hang friend soon\n",
              "4           at_us want trade someon houston ticket one\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZHxH3M_qUz3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = numpy.asarray(df.sentiment)\n",
        "df_features = df['SentimentText']\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec = TfidfVectorizer()\n",
        "vec.fit(df_features)\n",
        "features = vec.transform(df_features)\n",
        "features=features.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRGtMeW3Uz3F",
        "colab_type": "code",
        "colab": {},
        "outputId": "c46a95a9-5f3d-4a8a-8266-79f07cef357e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20, random_state=3, shuffle=True) \n",
        "print('train on %d instances, test on %d instances' % (len(features_train), len(features_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train on 80 instances, test on 20 instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um8mO9MOUz3J",
        "colab_type": "code",
        "colab": {},
        "outputId": "a25c15f4-25fb-427a-c4b2-cc6a2a072628"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "clf = KNeighborsClassifier(n_neighbors=23)\n",
        "# train the classifier using the training data\n",
        "clf.fit(features_train, labels_train)\n",
        "#predict class\n",
        "labels_pred = clf.predict(features_test)\n",
        "# compute accuracy using test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc_test = accuracy_score(labels_test, labels_pred)\n",
        "print (\"Test Accuracy:\", acc_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPgKU_9sUz3L",
        "colab_type": "code",
        "colab": {},
        "outputId": "35af020f-17e8-4338-8b2a-aadd2d3563af"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "clf = SVC(kernel=\"linear\")\n",
        "# train the classifier using the training data\n",
        "clf.fit(features_train, labels_train)\n",
        "#predict class\n",
        "labels_pred = clf.predict(features_test)\n",
        "# compute accuracy using test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc_test = accuracy_score(labels_test, labels_pred)\n",
        "print (\"Test Accuracy:\", acc_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfO0qd-KUz3Q",
        "colab_type": "code",
        "colab": {},
        "outputId": "599abf91-e541-4e05-9dd4-e80500583b5e"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "clf = BernoulliNB()\n",
        "# train the classifier using the training data\n",
        "clf.fit(features_train, labels_train)\n",
        "#predict class\n",
        "labels_pred = clf.predict(features_test)\n",
        "# compute accuracy using test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc_test = accuracy_score(labels_test, labels_pred)\n",
        "print (\"Test Accuracy:\", acc_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeFFsk7hUz3S",
        "colab_type": "code",
        "colab": {},
        "outputId": "3d1b3841-72a8-46be-f928-ed31c18928dd"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "# train the classifier using the training data\n",
        "clf.fit(features_train, labels_train)\n",
        "#predict class\n",
        "labels_pred = clf.predict(features_test)\n",
        "# compute accuracy using test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc_test = accuracy_score(labels_test, labels_pred)\n",
        "print (\"Test Accuracy:\", acc_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gfxRSd9Uz3W",
        "colab_type": "code",
        "colab": {},
        "outputId": "56159c7b-8cb0-4b81-d069-29fcf9f74546"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=998)\n",
        "# train the classifier using the training data\n",
        "clf.fit(features_train, labels_train)\n",
        "#predict class\n",
        "labels_pred = clf.predict(features_test)\n",
        "# compute accuracy using test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc_test = accuracy_score(labels_test, labels_pred)\n",
        "print (\"Test Accuracy:\", acc_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-neuDY8Uz3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}